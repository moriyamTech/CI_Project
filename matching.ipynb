{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_games_df = pd.read_csv('video_games_df_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Matching Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cate(matches, months):\n",
    "    cate_dict = {month: {m: [] for m in months[s + 1:]} for s, month in enumerate(months[:-1])}\n",
    "    \n",
    "    for start, month in enumerate(months[:-1]):\n",
    "        for other_month in months[start + 1:]:\n",
    "            relevant_matches = matches[month][other_month]\n",
    "            unit_sales = relevant_matches['current_sales'][0]\n",
    "            matched_sales = relevant_matches['matched_sales'][0]\n",
    "            mean_y = np.mean(matched_sales)\n",
    "            cate_dict[month][other_month] = unit_sales - mean_y\n",
    "            \n",
    "    return cate_dict\n",
    "\n",
    "\n",
    "def print_ates(cate_dict):\n",
    "    for month, other_months in cate_dict.items():\n",
    "        for other_month, cate_list in other_months.items():\n",
    "            ate = np.mean(cate_list)\n",
    "            print(f\"ATE from {month} to {other_month}: {ate}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = video_games_df['month']\n",
    "y = video_games_df['total_sales']\n",
    "X = video_games_df.drop(columns=['month', 'total_sales', 'img', 'na_sales', 'jp_sales', 'pal_sales',\n",
    "       'other_sales', 'release_date', 'last_update', 'iso_year',\n",
    "       'iso_week', 'year_week', 'title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_matches(video_games_df, k=1):\n",
    "    # Initialize an empty dictionary to store the closest matches for each month\n",
    "    closest_matches = {}\n",
    "    \n",
    "    # List of all unique months in the data\n",
    "    months = video_games_df['month'].unique()\n",
    "\n",
    "    # Loop over each month to find closest matches from other months\n",
    "    for month in months:\n",
    "        # Filter data for the current month and the rest of the months\n",
    "        current_month_data = video_games_df[video_games_df['month'] == month]\n",
    "        other_months_data = video_games_df[video_games_df['month'] != month]\n",
    "        \n",
    "        # Define feature sets for KNN\n",
    "        X_current = current_month_data.drop(columns=['month', 'total_sales', 'img', 'na_sales', \n",
    "                                                     'jp_sales', 'pal_sales', 'other_sales', \n",
    "                                                     'release_date', 'last_update', 'iso_year', \n",
    "                                                     'iso_week', 'year_week', 'title'])\n",
    "        X_other = other_months_data.drop(columns=['month', 'total_sales', 'img', 'na_sales', \n",
    "                                                  'jp_sales', 'pal_sales', 'other_sales', \n",
    "                                                  'release_date', 'last_update', 'iso_year', \n",
    "                                                  'iso_week', 'year_week', 'title'])\n",
    "        \n",
    "        # Initialize and fit the KNN model\n",
    "        knn = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
    "        knn.fit(X_other)\n",
    "        \n",
    "        # Find k closest matches for each entry in the current month\n",
    "        distances, indices = knn.kneighbors(X_current)\n",
    "        \n",
    "        # Store the results in the dictionary\n",
    "        closest_matches[month] = {\n",
    "            \"distances\": distances,\n",
    "            \"indices\": indices,\n",
    "            \"matches\": other_months_data.iloc[indices.flatten()]  # Closest matches data\n",
    "        }\n",
    "    \n",
    "    return closest_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_matches_with_sales(video_games_df, k=1):\n",
    "    # Initialize a dictionary to store the closest matches for each unit by month\n",
    "    closest_matches = {}\n",
    "\n",
    "    # List of all unique months in the data\n",
    "    months = video_games_df['month'].unique()\n",
    "\n",
    "    # Loop over each month to get the current month's units\n",
    "    for current_month in months:\n",
    "        current_month_data = video_games_df[video_games_df['month'] == current_month]\n",
    "        \n",
    "        # Drop non-feature columns from current month's data\n",
    "        X_current = current_month_data.drop(columns=['month', 'total_sales', 'img', 'na_sales', \n",
    "                                                     'jp_sales', 'pal_sales', 'other_sales', \n",
    "                                                     'release_date', 'last_update', 'iso_year', \n",
    "                                                     'iso_week', 'year_week', 'title'])\n",
    "        \n",
    "        # Initialize a dictionary to hold matches for each unit in the current month\n",
    "        closest_matches[current_month] = {}\n",
    "\n",
    "        # Loop over each of the other months\n",
    "        for other_month in tqdm(months):\n",
    "            if other_month == current_month:\n",
    "                continue  # Skip the current month itself\n",
    "            \n",
    "            # Get data from the other month\n",
    "            other_month_data = video_games_df[video_games_df['month'] == other_month]\n",
    "            X_other = other_month_data.drop(columns=['month', 'total_sales', 'img', 'na_sales', \n",
    "                                                     'jp_sales', 'pal_sales', 'other_sales', \n",
    "                                                     'release_date', 'last_update', 'iso_year', \n",
    "                                                     'iso_week', 'year_week', 'title'])\n",
    "            \n",
    "            # Initialize and fit the KNN model on the other month's data\n",
    "            knn = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
    "            knn.fit(X_other)\n",
    "            \n",
    "            # Find k closest matches for each unit in the current month from the other month\n",
    "            distances, indices = knn.kneighbors(X_current)\n",
    "            \n",
    "            # Store the results in the dictionary under the current and other month combination\n",
    "            closest_matches[current_month][other_month] = {\n",
    "                \"distances\": distances,\n",
    "                \"indices\": indices,\n",
    "                \"matches\": other_month_data.iloc[indices.flatten()],\n",
    "                \"current_sales\": current_month_data['total_sales'].values,  # Sales of current month units\n",
    "                \"matched_sales\": other_month_data['total_sales'].iloc[indices.flatten()].values  # Sales of matched units\n",
    "            }\n",
    "    \n",
    "    return closest_matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:38<00:00,  3.19s/it]\n",
      "100%|██████████| 12/12 [00:31<00:00,  2.60s/it]\n",
      "100%|██████████| 12/12 [00:33<00:00,  2.83s/it]\n",
      "100%|██████████| 12/12 [00:15<00:00,  1.31s/it]\n",
      "100%|██████████| 12/12 [00:24<00:00,  2.01s/it]\n",
      "100%|██████████| 12/12 [00:22<00:00,  1.88s/it]\n",
      "100%|██████████| 12/12 [00:20<00:00,  1.68s/it]\n",
      "100%|██████████| 12/12 [00:35<00:00,  2.99s/it]\n",
      "100%|██████████| 12/12 [00:14<00:00,  1.24s/it]\n",
      "100%|██████████| 12/12 [00:13<00:00,  1.11s/it]\n",
      "100%|██████████| 12/12 [00:17<00:00,  1.45s/it]\n",
      "100%|██████████| 12/12 [00:23<00:00,  1.93s/it]\n"
     ]
    }
   ],
   "source": [
    "closest_matches = find_closest_matches_with_sales(video_games_df, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE from 9 to 11: 20.31\n",
      "ATE from 9 to 10: 20.27\n",
      "ATE from 9 to 4: 19.76\n",
      "ATE from 9 to 6: 20.14\n",
      "ATE from 9 to 5: 20.31\n",
      "ATE from 9 to 8: 20.29\n",
      "ATE from 9 to 3: 20.23\n",
      "ATE from 9 to 1: 19.75\n",
      "ATE from 9 to 7: 19.87\n",
      "ATE from 9 to 2: 20.32\n",
      "ATE from 9 to 12: 20.22\n",
      "ATE from 11 to 10: 19.38\n",
      "ATE from 11 to 4: 19.26\n",
      "ATE from 11 to 6: 19.39\n",
      "ATE from 11 to 5: 19.39\n",
      "ATE from 11 to 8: 18.57\n",
      "ATE from 11 to 3: 19.240000000000002\n",
      "ATE from 11 to 1: 19.36\n",
      "ATE from 11 to 7: 19.38\n",
      "ATE from 11 to 2: 19.37\n",
      "ATE from 11 to 12: 19.32\n",
      "ATE from 10 to 4: 15.87\n",
      "ATE from 10 to 6: 16.04\n",
      "ATE from 10 to 5: 15.999999999999998\n",
      "ATE from 10 to 8: 15.889999999999999\n",
      "ATE from 10 to 3: 15.729999999999999\n",
      "ATE from 10 to 1: 15.959999999999999\n",
      "ATE from 10 to 7: 16.09\n",
      "ATE from 10 to 2: 16.15\n",
      "ATE from 10 to 12: 15.999999999999998\n",
      "ATE from 4 to 6: 11.07\n",
      "ATE from 4 to 5: 11.0\n",
      "ATE from 4 to 8: 11.08\n",
      "ATE from 4 to 3: 11.03\n",
      "ATE from 4 to 1: 11.07\n",
      "ATE from 4 to 7: 11.09\n",
      "ATE from 4 to 2: 11.09\n",
      "ATE from 4 to 12: 11.0\n",
      "ATE from 6 to 5: 7.8\n",
      "ATE from 6 to 8: 7.33\n",
      "ATE from 6 to 3: 7.88\n",
      "ATE from 6 to 1: 7.9\n",
      "ATE from 6 to 7: 7.96\n",
      "ATE from 6 to 2: 7.94\n",
      "ATE from 6 to 12: 7.93\n",
      "ATE from 5 to 8: 6.44\n",
      "ATE from 5 to 3: 6.64\n",
      "ATE from 5 to 1: 6.69\n",
      "ATE from 5 to 7: 6.5200000000000005\n",
      "ATE from 5 to 2: 6.62\n",
      "ATE from 5 to 12: 6.42\n",
      "ATE from 8 to 3: 5.54\n",
      "ATE from 8 to 1: 4.15\n",
      "ATE from 8 to 7: 5.51\n",
      "ATE from 8 to 2: 5.140000000000001\n",
      "ATE from 8 to 12: 5.140000000000001\n",
      "ATE from 3 to 1: 5.33\n",
      "ATE from 3 to 7: 5.33\n",
      "ATE from 3 to 2: 5.319999999999999\n",
      "ATE from 3 to 12: 5.279999999999999\n",
      "ATE from 1 to 7: 5.1\n",
      "ATE from 1 to 2: 5.09\n",
      "ATE from 1 to 12: 5.01\n",
      "ATE from 7 to 2: 4.4399999999999995\n",
      "ATE from 7 to 12: 4.29\n",
      "ATE from 2 to 12: 4.279999999999999\n"
     ]
    }
   ],
   "source": [
    "cate_dict = cate(closest_matches, video_games_df['month'].unique())\n",
    "print_ates(cate_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.26it/s]\n",
      "100%|██████████| 12/12 [00:14<00:00,  1.23s/it]\n",
      "100%|██████████| 12/12 [00:17<00:00,  1.49s/it]\n",
      "100%|██████████| 12/12 [00:10<00:00,  1.10it/s]\n",
      "100%|██████████| 12/12 [00:13<00:00,  1.10s/it]\n",
      "100%|██████████| 12/12 [00:10<00:00,  1.12it/s]\n",
      "100%|██████████| 12/12 [00:12<00:00,  1.03s/it]\n",
      "100%|██████████| 12/12 [00:13<00:00,  1.13s/it]\n",
      "100%|██████████| 12/12 [00:10<00:00,  1.11it/s]\n",
      "100%|██████████| 12/12 [00:10<00:00,  1.18it/s]\n",
      "100%|██████████| 12/12 [00:11<00:00,  1.04it/s]\n",
      "100%|██████████| 12/12 [00:10<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "closest_matches = find_closest_matches_with_sales(video_games_df, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE from 9 to 11: 20.31\n",
      "ATE from 9 to 10: 20.27\n",
      "ATE from 9 to 4: 19.76\n",
      "ATE from 9 to 6: 20.14\n",
      "ATE from 9 to 5: 20.31\n",
      "ATE from 9 to 8: 20.29\n",
      "ATE from 9 to 3: 20.23\n",
      "ATE from 9 to 1: 19.75\n",
      "ATE from 9 to 7: 19.87\n",
      "ATE from 9 to 2: 20.32\n",
      "ATE from 9 to 12: 20.22\n",
      "ATE from 11 to 10: 19.38\n",
      "ATE from 11 to 4: 19.26\n",
      "ATE from 11 to 6: 19.39\n",
      "ATE from 11 to 5: 19.39\n",
      "ATE from 11 to 8: 18.57\n",
      "ATE from 11 to 3: 19.240000000000002\n",
      "ATE from 11 to 1: 19.36\n",
      "ATE from 11 to 7: 19.38\n",
      "ATE from 11 to 2: 19.37\n",
      "ATE from 11 to 12: 19.32\n",
      "ATE from 10 to 4: 15.87\n",
      "ATE from 10 to 6: 16.04\n",
      "ATE from 10 to 5: 15.999999999999998\n",
      "ATE from 10 to 8: 15.889999999999999\n",
      "ATE from 10 to 3: 15.729999999999999\n",
      "ATE from 10 to 1: 15.959999999999999\n",
      "ATE from 10 to 7: 16.09\n",
      "ATE from 10 to 2: 16.15\n",
      "ATE from 10 to 12: 15.999999999999998\n",
      "ATE from 4 to 6: 11.07\n",
      "ATE from 4 to 5: 11.0\n",
      "ATE from 4 to 8: 11.08\n",
      "ATE from 4 to 3: 11.03\n",
      "ATE from 4 to 1: 11.07\n",
      "ATE from 4 to 7: 11.09\n",
      "ATE from 4 to 2: 11.09\n",
      "ATE from 4 to 12: 11.0\n",
      "ATE from 6 to 5: 7.8\n",
      "ATE from 6 to 8: 7.33\n",
      "ATE from 6 to 3: 7.88\n",
      "ATE from 6 to 1: 7.9\n",
      "ATE from 6 to 7: 7.96\n",
      "ATE from 6 to 2: 7.94\n",
      "ATE from 6 to 12: 7.93\n",
      "ATE from 5 to 8: 6.44\n",
      "ATE from 5 to 3: 6.64\n",
      "ATE from 5 to 1: 6.69\n",
      "ATE from 5 to 7: 6.5200000000000005\n",
      "ATE from 5 to 2: 6.62\n",
      "ATE from 5 to 12: 6.42\n",
      "ATE from 8 to 3: 5.54\n",
      "ATE from 8 to 1: 4.15\n",
      "ATE from 8 to 7: 5.51\n",
      "ATE from 8 to 2: 5.140000000000001\n",
      "ATE from 8 to 12: 5.140000000000001\n",
      "ATE from 3 to 1: 5.33\n",
      "ATE from 3 to 7: 5.33\n",
      "ATE from 3 to 2: 5.319999999999999\n",
      "ATE from 3 to 12: 5.279999999999999\n",
      "ATE from 1 to 7: 5.1\n",
      "ATE from 1 to 2: 5.09\n",
      "ATE from 1 to 12: 5.01\n",
      "ATE from 7 to 2: 4.4399999999999995\n",
      "ATE from 7 to 12: 4.29\n",
      "ATE from 2 to 12: 4.279999999999999\n"
     ]
    }
   ],
   "source": [
    "cate_dict = cate(closest_matches, video_games_df['month'].unique())\n",
    "print_ates(cate_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Five Neigbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.24it/s]\n",
      "100%|██████████| 12/12 [00:18<00:00,  1.53s/it]\n",
      "100%|██████████| 12/12 [00:18<00:00,  1.56s/it]\n",
      "100%|██████████| 12/12 [00:08<00:00,  1.48it/s]\n",
      "100%|██████████| 12/12 [00:13<00:00,  1.12s/it]\n",
      "100%|██████████| 12/12 [00:11<00:00,  1.04it/s]\n",
      "100%|██████████| 12/12 [00:11<00:00,  1.06it/s]\n",
      "100%|██████████| 12/12 [00:15<00:00,  1.26s/it]\n",
      "100%|██████████| 12/12 [00:10<00:00,  1.19it/s]\n",
      "100%|██████████| 12/12 [00:10<00:00,  1.14it/s]\n",
      "100%|██████████| 12/12 [00:13<00:00,  1.09s/it]\n",
      "100%|██████████| 12/12 [00:10<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "closest_matches = find_closest_matches_with_sales(video_games_df, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE from 9 to 11: 20.31\n",
      "ATE from 9 to 10: 20.27\n",
      "ATE from 9 to 4: 19.76\n",
      "ATE from 9 to 6: 20.14\n",
      "ATE from 9 to 5: 20.31\n",
      "ATE from 9 to 8: 20.29\n",
      "ATE from 9 to 3: 20.23\n",
      "ATE from 9 to 1: 19.75\n",
      "ATE from 9 to 7: 19.87\n",
      "ATE from 9 to 2: 20.32\n",
      "ATE from 9 to 12: 20.22\n",
      "ATE from 11 to 10: 19.38\n",
      "ATE from 11 to 4: 19.26\n",
      "ATE from 11 to 6: 19.39\n",
      "ATE from 11 to 5: 19.39\n",
      "ATE from 11 to 8: 18.57\n",
      "ATE from 11 to 3: 19.240000000000002\n",
      "ATE from 11 to 1: 19.36\n",
      "ATE from 11 to 7: 19.38\n",
      "ATE from 11 to 2: 19.37\n",
      "ATE from 11 to 12: 19.32\n",
      "ATE from 10 to 4: 15.87\n",
      "ATE from 10 to 6: 16.04\n",
      "ATE from 10 to 5: 15.999999999999998\n",
      "ATE from 10 to 8: 15.889999999999999\n",
      "ATE from 10 to 3: 15.729999999999999\n",
      "ATE from 10 to 1: 15.959999999999999\n",
      "ATE from 10 to 7: 16.09\n",
      "ATE from 10 to 2: 16.15\n",
      "ATE from 10 to 12: 15.999999999999998\n",
      "ATE from 4 to 6: 11.07\n",
      "ATE from 4 to 5: 11.0\n",
      "ATE from 4 to 8: 11.08\n",
      "ATE from 4 to 3: 11.03\n",
      "ATE from 4 to 1: 11.07\n",
      "ATE from 4 to 7: 11.09\n",
      "ATE from 4 to 2: 11.09\n",
      "ATE from 4 to 12: 11.0\n",
      "ATE from 6 to 5: 7.8\n",
      "ATE from 6 to 8: 7.33\n",
      "ATE from 6 to 3: 7.88\n",
      "ATE from 6 to 1: 7.9\n",
      "ATE from 6 to 7: 7.96\n",
      "ATE from 6 to 2: 7.94\n",
      "ATE from 6 to 12: 7.93\n",
      "ATE from 5 to 8: 6.44\n",
      "ATE from 5 to 3: 6.64\n",
      "ATE from 5 to 1: 6.69\n",
      "ATE from 5 to 7: 6.5200000000000005\n",
      "ATE from 5 to 2: 6.62\n",
      "ATE from 5 to 12: 6.42\n",
      "ATE from 8 to 3: 5.54\n",
      "ATE from 8 to 1: 4.15\n",
      "ATE from 8 to 7: 5.51\n",
      "ATE from 8 to 2: 5.140000000000001\n",
      "ATE from 8 to 12: 5.140000000000001\n",
      "ATE from 3 to 1: 5.33\n",
      "ATE from 3 to 7: 5.33\n",
      "ATE from 3 to 2: 5.319999999999999\n",
      "ATE from 3 to 12: 5.279999999999999\n",
      "ATE from 1 to 7: 5.1\n",
      "ATE from 1 to 2: 5.09\n",
      "ATE from 1 to 12: 5.01\n",
      "ATE from 7 to 2: 4.4399999999999995\n",
      "ATE from 7 to 12: 4.29\n",
      "ATE from 2 to 12: 4.279999999999999\n"
     ]
    }
   ],
   "source": [
    "cate_dict = cate(closest_matches, video_games_df['month'].unique())\n",
    "print_ates(cate_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propensity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moriy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 1. Preprocess the data\n",
    "# Impute missing values for 'critic_score'\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "video_games_df['critic_score'] = imputer.fit_transform(video_games_df[['critic_score']])\n",
    "\n",
    "# Convert categorical variables to one-hot encoding\n",
    "cat_columns = ['console', 'genre', 'publisher', 'developer']\n",
    "video_games_df = pd.get_dummies(video_games_df, columns=cat_columns, drop_first=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = video_games_df.drop(columns=['month', 'total_sales', 'img', 'na_sales', 'jp_sales', 'pal_sales',\n",
    "       'other_sales', 'release_date', 'last_update', 'iso_year',\n",
    "       'iso_week', 'year_week', 'title'])\n",
    "y = video_games_df['month']\n",
    "\n",
    "# 2. Estimate Propensity Scores\n",
    "# Fit a multinomial logistic regression for propensity scores\n",
    "logistic_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "logistic_model.fit(X, y)\n",
    "propensity_scores = logistic_model.predict_proba(X)  # Each row has probabilities for each 'month'\n",
    "\n",
    "# 3. Match Units\n",
    "# Compute pairwise distances based on propensity scores\n",
    "# This creates a distance matrix for matching similar propensity scores across months\n",
    "distances = pairwise_distances(propensity_scores, metric='euclidean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "354644224 requested and 0 written",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpropensity_scores.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, propensity_scores, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Text format (optional)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Save distances\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdistances.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Binary format\u001b[39;00m\n\u001b[0;32m      9\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistances.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, distances, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Text format (optional)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\numpy\\lib\\npyio.py:546\u001b[0m, in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[0;32m    545\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(arr)\n\u001b[1;32m--> 546\u001b[0m     \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfix_imports\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfix_imports\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\numpy\\lib\\format.py:730\u001b[0m, in \u001b[0;36mwrite_array\u001b[1;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    729\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[1;32m--> 730\u001b[0m         \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39mnditer(\n\u001b[0;32m    733\u001b[0m                 array, flags\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexternal_loop\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuffered\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzerosize_ok\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    734\u001b[0m                 buffersize\u001b[38;5;241m=\u001b[39mbuffersize, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mOSError\u001b[0m: 354644224 requested and 0 written"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Save propensity scores\n",
    "np.save(\"propensity_scores.npy\", propensity_scores)  # Binary format\n",
    "np.savetxt(\"propensity_scores.csv\", propensity_scores, delimiter=\",\")  # Text format (optional)\n",
    "\n",
    "# Save distances\n",
    "np.save(\"distances.npy\", distances)  # Binary format\n",
    "np.savetxt(\"distances.csv\", distances, delimiter=\",\")  # Text format (optional)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
