{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (4.45.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->transformers) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting groq\n",
      "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from groq) (4.3.0)\n",
      "Collecting distro<2,>=1.7.0 (from groq)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from groq) (2.6.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from groq) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from anyio<5,>=3.5.0->groq) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from anyio<5,>=3.5.0->groq) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from httpx<1,>=0.23.0->groq) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pydantic<3,>=1.9.0->groq) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pydantic<3,>=1.9.0->groq) (2.16.2)\n",
      "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: distro, groq\n",
      "Successfully installed distro-1.9.0 groq-0.11.0\n",
      "Collecting groq\n",
      "  Using cached groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from groq) (4.3.0)\n",
      "Collecting distro<2,>=1.7.0 (from groq)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from groq) (2.6.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from groq) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from anyio<5,>=3.5.0->groq) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from anyio<5,>=3.5.0->groq) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from httpx<1,>=0.23.0->groq) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pydantic<3,>=1.9.0->groq) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pydantic<3,>=1.9.0->groq) (2.16.2)\n",
      "Using cached groq-0.11.0-py3-none-any.whl (106 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: distro, groq\n",
      "Successfully installed distro-1.9.0 groq-0.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\moriy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>title</th>\n",
       "      <th>console</th>\n",
       "      <th>genre</th>\n",
       "      <th>publisher</th>\n",
       "      <th>developer</th>\n",
       "      <th>critic_score</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>na_sales</th>\n",
       "      <th>jp_sales</th>\n",
       "      <th>pal_sales</th>\n",
       "      <th>other_sales</th>\n",
       "      <th>release_date</th>\n",
       "      <th>last_update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/games/boxart/full_6510540AmericaFrontccc.jpg</td>\n",
       "      <td>Grand Theft Auto V</td>\n",
       "      <td>PS3</td>\n",
       "      <td>Action</td>\n",
       "      <td>Rockstar Games</td>\n",
       "      <td>Rockstar North</td>\n",
       "      <td>9.4</td>\n",
       "      <td>20.32</td>\n",
       "      <td>6.37</td>\n",
       "      <td>0.99</td>\n",
       "      <td>9.85</td>\n",
       "      <td>3.12</td>\n",
       "      <td>17-09-2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/games/boxart/full_5563178AmericaFrontccc.jpg</td>\n",
       "      <td>Grand Theft Auto V</td>\n",
       "      <td>PS4</td>\n",
       "      <td>Action</td>\n",
       "      <td>Rockstar Games</td>\n",
       "      <td>Rockstar North</td>\n",
       "      <td>9.7</td>\n",
       "      <td>19.39</td>\n",
       "      <td>6.06</td>\n",
       "      <td>0.60</td>\n",
       "      <td>9.71</td>\n",
       "      <td>3.02</td>\n",
       "      <td>18-11-2014</td>\n",
       "      <td>03-01-2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/games/boxart/827563ccc.jpg</td>\n",
       "      <td>Grand Theft Auto: Vice City</td>\n",
       "      <td>PS2</td>\n",
       "      <td>Action</td>\n",
       "      <td>Rockstar Games</td>\n",
       "      <td>Rockstar North</td>\n",
       "      <td>9.6</td>\n",
       "      <td>16.15</td>\n",
       "      <td>8.41</td>\n",
       "      <td>0.47</td>\n",
       "      <td>5.49</td>\n",
       "      <td>1.78</td>\n",
       "      <td>28-10-2002</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/games/boxart/full_9218923AmericaFrontccc.jpg</td>\n",
       "      <td>Grand Theft Auto V</td>\n",
       "      <td>X360</td>\n",
       "      <td>Action</td>\n",
       "      <td>Rockstar Games</td>\n",
       "      <td>Rockstar North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.86</td>\n",
       "      <td>9.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>5.33</td>\n",
       "      <td>1.42</td>\n",
       "      <td>17-09-2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/games/boxart/full_4990510AmericaFrontccc.jpg</td>\n",
       "      <td>Call of Duty: Black Ops 3</td>\n",
       "      <td>PS4</td>\n",
       "      <td>Shooter</td>\n",
       "      <td>Activision</td>\n",
       "      <td>Treyarch</td>\n",
       "      <td>8.1</td>\n",
       "      <td>15.09</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0.41</td>\n",
       "      <td>6.05</td>\n",
       "      <td>2.44</td>\n",
       "      <td>06-11-2015</td>\n",
       "      <td>14-01-2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             img                        title  \\\n",
       "0  /games/boxart/full_6510540AmericaFrontccc.jpg           Grand Theft Auto V   \n",
       "1  /games/boxart/full_5563178AmericaFrontccc.jpg           Grand Theft Auto V   \n",
       "2                    /games/boxart/827563ccc.jpg  Grand Theft Auto: Vice City   \n",
       "3  /games/boxart/full_9218923AmericaFrontccc.jpg           Grand Theft Auto V   \n",
       "4  /games/boxart/full_4990510AmericaFrontccc.jpg    Call of Duty: Black Ops 3   \n",
       "\n",
       "  console    genre       publisher       developer  critic_score  total_sales  \\\n",
       "0     PS3   Action  Rockstar Games  Rockstar North           9.4        20.32   \n",
       "1     PS4   Action  Rockstar Games  Rockstar North           9.7        19.39   \n",
       "2     PS2   Action  Rockstar Games  Rockstar North           9.6        16.15   \n",
       "3    X360   Action  Rockstar Games  Rockstar North           NaN        15.86   \n",
       "4     PS4  Shooter      Activision        Treyarch           8.1        15.09   \n",
       "\n",
       "   na_sales  jp_sales  pal_sales  other_sales release_date last_update  \n",
       "0      6.37      0.99       9.85         3.12   17-09-2013         NaN  \n",
       "1      6.06      0.60       9.71         3.02   18-11-2014  03-01-2018  \n",
       "2      8.41      0.47       5.49         1.78   28-10-2002         NaN  \n",
       "3      9.06      0.06       5.33         1.42   17-09-2013         NaN  \n",
       "4      6.18      0.41       6.05         2.44   06-11-2015  14-01-2018  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_games_df = pd.read_csv('Video Games Data.csv\\Video Games Data.csv')\n",
    "video_games_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64017"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(video_games_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_week_identifier(df, date_column):\n",
    "    # Ensure the date_column is in datetime format\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "    \n",
    "    # Extract the ISO calendar year and week number\n",
    "    df['iso_year'] = df[date_column].dt.isocalendar().year\n",
    "    df['iso_week'] = df[date_column].dt.isocalendar().week\n",
    "    \n",
    "    # Create a unique identifier for the year and week combination\n",
    "    df['year_week'] = df['iso_year'].astype(str) + '-W' + df['iso_week'].astype(str)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_niche(columns, df):\n",
    "    # Group the DataFrame by the specified columns\n",
    "    group_counts = df.groupby(columns).size().reset_index(name='niche_count')\n",
    "    \n",
    "    # Merge the counts back to the original DataFrame based on the same columns\n",
    "    df = df.merge(group_counts, on=columns, how='left')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = 'YOUR_OPENAI_API_KEY'\n",
    "\n",
    "# Function to use ChatGPT (GPT-3.5-turbo) to check if the game is part of a franchise\n",
    "def check_if_franchise(game_title):\n",
    "    prompt = f\"Is the video game '{game_title}' part of a franchise? Respond with 'Yes' or 'No'.\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",  # Use ChatGPT API\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=3,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    answer = response.choices[0].message['content'].strip()\n",
    "    return 1 if answer.lower() == 'yes' else 0  # Return 1 for Yes, 0 for No\n",
    "\n",
    "# Function to check if a game is the first in its franchise\n",
    "def check_if_original(game_title, release_date, df):\n",
    "    # Filter games that are marked as part of a franchise\n",
    "    franchise_games = df[df['Is Franchise'] == 1]\n",
    "    \n",
    "    # Identify games that are likely part of the same franchise (based on partial name match)\n",
    "    same_franchise_games = franchise_games[franchise_games['Game Title'].str.contains(game_title.split()[0], regex=False)]\n",
    "    \n",
    "    if same_franchise_games.empty:\n",
    "        return 0  # If no other games are part of the franchise, it's the original (0)\n",
    "    \n",
    "    # Check if the current game's release date is the earliest among those in the franchise\n",
    "    earliest_date = same_franchise_games['Release Date'].min()\n",
    "    if release_date == earliest_date:\n",
    "        return 0  # Original game (0)\n",
    "    else:\n",
    "        return 1  # Not the original (1)\n",
    "\n",
    "# Example dataset (replace this with your actual data)\n",
    "data = {\n",
    "    'Game Title': ['Assassin\\'s Creed', 'Assassin\\'s Creed II', 'The Witcher', 'The Witcher 2'],\n",
    "    'Release Date': ['2007-11-13', '2009-11-17', '2007-10-26', '2011-05-17']\n",
    "}\n",
    "\n",
    "# Convert the data into a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply the LLM to determine if each game is part of a franchise (1 for Yes, 0 for No)\n",
    "df['Is Franchise'] = df['Game Title'].apply(lambda title: check_if_franchise(title))\n",
    "\n",
    "# Apply the function to check if the game is the original in its franchise (0 for original, 1 for not original)\n",
    "df['Is Original in Franchise'] = df.apply(lambda row: check_if_original(row['Game Title'], row['Release Date'], df), axis=1)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moriy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some examples that can help you determine if a video game is part of a franchise:\n",
      "Is the video game 'Assassin's Creed' part of a franchise? Answer only Yes or No\n",
      "No\n",
      "Is the video game 'Assassin's Creed' II part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Is the video game The 'Witcher' part of a franchise? Answer only Yes or No\n",
      "No\n",
      "Is the video game The 'Witcher 2' part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Here is the question, you are allowed to answer in one word:\n",
      "Is the video game 'Gaurdian' part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Is the video game 'Grimm' part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Is the video game 'Grimm 2' part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Here is the question, you are allowed to answer in two words:\n",
      "Is the video game 'Grimm 3' part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Is the video game 'Grimm 4' part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Here\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some examples that can help you determine if a video game is part of a franchise:\n",
      "Is the video game 'Assassin's Creed' part of a franchise? Answer only Yes or No\n",
      "No\n",
      "Is the video game 'Assassin's Creed' II part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Is the video game The 'Witcher' part of a franchise? Answer only Yes or No\n",
      "No\n",
      "Is the video game The 'Witcher 2' part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Here is the question, you are allowed to answer in one word:\n",
      "Is the video game 'Gaurdian 2' part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Is the video game 'Gaurdian 3' part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Here is the question, you are allowed to answer in one word:\n",
      "Is the video game 'Gravity Rush' part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Here is the question, you are allowed to answer in one word:\n",
      "Is the video game 'Gravity Rush 2' part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Here is the question, you are allowed\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some examples that can help you determine if a video game is part of a franchise:\n",
      "Is the video game 'Assassin's Creed' part of a franchise? Answer only Yes or No\n",
      "No\n",
      "Is the video game 'Assassin's Creed' II part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Is the video game The 'Witcher' part of a franchise? Answer only Yes or No\n",
      "No\n",
      "Is the video game The 'Witcher 2' part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Here is the question, you are allowed to answer in one word:\n",
      "Is the video game 'Shoe' part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Is the video game 'Shoe 2' part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Here is the question, you are allowed to answer in two words:\n",
      "Is the video game 'Shoe 3' part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Here is the question, you are allowed to answer in three words:\n",
      "Is the video game 'Shoe 4' part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Here is the question, you are allowed to answer in four\n",
      "--------------------------------------------------------\n",
      "Here are some examples that can help you determine if a video game is part of a franchise:\n",
      "Is the video game 'Assassin's Creed' part of a franchise? Answer only Yes or No\n",
      "No\n",
      "Is the video game 'Assassin's Creed' II part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Is the video game The 'Witcher' part of a franchise? Answer only Yes or No\n",
      "No\n",
      "Is the video game The 'Witcher 2' part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Here is the question, you are allowed to answer in one word:\n",
      "Is the video game 'Shoe vol.2' part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Is the video game 'Shoe vol.3' part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Here is the question, you are allowed to answer in one word:\n",
      "Is the video game 'Shoe vol.4' part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Here is the question, you are allowed to answer in one word:\n",
      "Is the video game 'Shoe vol.5' part of a franchise? Answer only Yes or No\n",
      "Yes\n",
      "Here is the\n",
      "--------------------------------------------------------\n",
      "   Game Title Release Date Is Franchise Is Original in Franchise\n",
      "0    Gaurdian   2007-11-13         Here                       No\n",
      "1  Gaurdian 2   2009-11-17      allowed                       No\n",
      "2        Shoe   2007-10-26         four                       No\n",
      "3  Shoe vol.2   2011-05-17          the                       No\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load the pre-trained GPT-2 model and tokenizer\n",
    "model_name = 'gpt2'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# Function to generate a response using GPT-2\n",
    "def generate_gpt2_response(prompt):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    outputs = model.generate(inputs, max_length=256, num_return_sequences=1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response.strip()\n",
    "\n",
    "# Function to determine if a game is part of a franchise using GPT-2\n",
    "def check_if_franchise(game_title):\n",
    "    prompt = \"Here are some examples that can help you determine if a video game is part of a franchise:\\n\"\n",
    "    prompt += \"Is the video game 'Assassin's Creed' part of a franchise? Answer only Yes or No\\n\"\n",
    "    prompt += \"No\\n\"\n",
    "    prompt += f\"Is the video game 'Assassin's Creed' II part of a franchise? Answer only Yes or No\\n\"\n",
    "    prompt += \"Yes\\n\"\n",
    "    prompt += f\"Is the video game The 'Witcher' part of a franchise? Answer only Yes or No\\n\"\n",
    "    prompt += \"No\\n\"\n",
    "    prompt += f\"Is the video game The 'Witcher 2' part of a franchise? Answer only Yes or No\\n\"\n",
    "    prompt += \"Yes\\n\"\n",
    "    prompt += \"Here is the question, you are allowed to answer in one word:\\n\"\n",
    "    prompt += f\"Is the video game '{game_title}' part of a franchise? Answer only Yes or No\"\n",
    "    response = generate_gpt2_response(prompt)\n",
    "    print(response)\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    # Post-process the response to extract Yes/No\n",
    "    return response.split()[-1] if response else \"No\"\n",
    "\n",
    "# Function to check if a game is the first in a franchise\n",
    "def check_if_original(game_title, release_date, df):\n",
    "    franchise_games = df[df['Is Franchise'] == 'Yes']  # Filter games part of the franchise\n",
    "    same_franchise_games = franchise_games[franchise_games['Game Title'].str.contains(game_title.split()[0])]\n",
    "    if same_franchise_games.empty:\n",
    "        return 'No'  # If no previous game, it's the first in the franchise\n",
    "    earliest_date = same_franchise_games['Release Date'].min()\n",
    "    if release_date == earliest_date:\n",
    "        return 'No'  # First game of the franchise\n",
    "    else:\n",
    "        return 'Yes'\n",
    "\n",
    "# Example dataset (replace this with your actual data)\n",
    "data = {\n",
    "    'Game Title': ['Gaurdian', 'Gaurdian 2', 'Shoe', 'Shoe vol.2'],\n",
    "    'Release Date': ['2007-11-13', '2009-11-17', '2007-10-26', '2011-05-17']\n",
    "}\n",
    "\n",
    "# Convert data into a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply the GPT-2 model to determine if each game is part of a franchise\n",
    "df['Is Franchise'] = df['Game Title'].apply(lambda title: check_if_franchise(title))\n",
    "\n",
    "# Apply logic to determine if a game is the original in its franchise\n",
    "df['Is Original in Franchise'] = df.apply(lambda row: check_if_original(row['Game Title'], row['Release Date'], df), axis=1)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_strings = ['II', 'III', 'IV', 'V', 'VI', 'VII', 'VIII', 'IX', 'X']\n",
    "\n",
    "def check_if_sequel(game_title):\n",
    "    for cont_str in cont_strings:\n",
    "        if cont_str in game_title:\n",
    "            return True\n",
    "    \n",
    "    if any(char.isdigit() for char in game_title):\n",
    "        return True    \n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_subname(game_title1, game_title2):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    title_list1 = game_title1.split()\n",
    "    title_list2 = game_title2.split()\n",
    "    \n",
    "    # Remove stopwords from both lists\n",
    "    filtered_title1 = [word.lower() for word in title_list1 if word.lower() not in stop_words]\n",
    "    filtered_title2 = [word.lower() for word in title_list2 if word.lower() not in stop_words]\n",
    "    \n",
    "    # Check if any word from filtered_title1 is in filtered_title2\n",
    "    for word in filtered_title1:\n",
    "        if word in filtered_title2:\n",
    "            return True  # A match found\n",
    "    \n",
    "    return False  # No match found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "print(check_subname(\"The Legend of Zelda\", \"Legend of Zelda: Breath of the Wild\"))  # Should return True\n",
    "print(check_subname(\"Super Mario\", \"Donkey Kong Country\"))  # Should return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last check with GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moriy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained GPT-2 model and tokenizer\n",
    "model_name = 'gpt2'\n",
    "model_name = 'vicgalle/gpt2-open-instruct-v1'\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "# model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vicgalle/gpt2-open-instruct-v1\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"vicgalle/gpt2-open-instruct-v1\")\n",
    "\n",
    "# # Function to generate a response using GPT-2\n",
    "# def generate_gpt2_response(prompt):\n",
    "#     inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "#     outputs = model.generate(inputs, max_length=256, num_return_sequences=1)\n",
    "#     response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "#     return response.strip()\n",
    "\n",
    "# Function to generate a response using GPT-2\n",
    "def generate_gpt2_response(prompt):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    \n",
    "    # Pass the pad_token_id explicitly to avoid warnings\n",
    "    outputs = model.generate(inputs, \n",
    "                             max_length=len(inputs[0]) + 2, \n",
    "                             num_return_sequences=1, \n",
    "                             top_k=50,                  # Limits the sampling pool to the top k tokens\n",
    "                             top_p=0.9,\n",
    "                             do_sample=True,\n",
    "                             pad_token_id=tokenizer.eos_token_id)\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response.strip()\n",
    "\n",
    "# Function to determine if a game is part of a franchise using GPT-2\n",
    "def check_if_franchise(game_title1, game_title2):\n",
    "    system_prompt = f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Here are two video game titles:\n",
    "1. {game_title1}\n",
    "2. {game_title2}\n",
    "Are these games part of the same franchise? Respond only with 'Yes' or 'No'.\n",
    "    \n",
    "### Response:\n",
    "    \"\"\"\n",
    "      \n",
    "    response = generate_gpt2_response(system_prompt)\n",
    "    print(response)\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    # Post-process the response to extract Yes/No\n",
    "    return response.split()[-1] if response else \"No\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "\n",
      "Here are two video game titles:\n",
      "1. The Legend of Zelda\n",
      "2. Legend of Zelda: Breath of the Wild\n",
      "Are these games part of the same franchise? Respond only with 'Yes' or 'No'.\n",
      "--------------------------------------------------------\n",
      "'No'.\n",
      "--------------------------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "\n",
      "Here are two video game titles:\n",
      "1. Super Mario\n",
      "2. Donkey Kong Country\n",
      "Are these games part of the same franchise? Respond only with 'Yes' or 'No'.\n",
      "--------------------------------------------------------\n",
      "'No'.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "print(check_if_franchise(\"The Legend of Zelda\", \"Legend of Zelda: Breath of the Wild\"))  # Should return True\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(check_if_franchise(\"Super Mario\", \"Donkey Kong Country\"))  # Should return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\moriy\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Log in using your token\n",
    "login(\"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\")\n",
    "\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, List\n",
    "from groq import Groq\n",
    "\n",
    "# Get a free API key from https://console.groq.com/keys\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "LLAMA3_70B_INSTRUCT = \"llama3-70b-8192\"\n",
    "LLAMA3_8B_INSTRUCT = \"llama3-8b-8192\"\n",
    "CODELLAMA_70B_INSTRUCT = \"codellama-70b\"\n",
    "\n",
    "DEFAULT_MODEL = LLAMA3_70B_INSTRUCT\n",
    "# DEFAULT_MODEL = CODELLAMA_70B_INSTRUCT\n",
    "\n",
    "client = Groq()\n",
    "\n",
    "def assistant(content: str):\n",
    "    return { \"role\": \"assistant\", \"content\": content }\n",
    "\n",
    "def user(content: str):\n",
    "    return { \"role\": \"user\", \"content\": content }\n",
    "\n",
    "def chat_completion(\n",
    "    messages: List[Dict],\n",
    "    model = DEFAULT_MODEL,\n",
    "    temperature: float = 0.6,\n",
    "    top_p: float = 0.9,\n",
    ") -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "        \n",
    "\n",
    "def completion(\n",
    "    prompt: str,\n",
    "    model: str = DEFAULT_MODEL,\n",
    "    temperature: float = 0.6,\n",
    "    top_p: float = 0.9,\n",
    ") -> str:\n",
    "    return chat_completion(\n",
    "        [user(prompt)],\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "    )\n",
    "    \n",
    "def complete_and_print(prompt: str, model: str = DEFAULT_MODEL):\n",
    "    print(f'==============\\n{prompt}\\n==============')\n",
    "    response = completion(prompt, model)\n",
    "    print(response, end='\\n\\n')\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============\n",
      "The typical color of the sky is: \n",
      "==============\n",
      "Blue!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complete_and_print(\"The typical color of the sky is: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_franchise(game_title1, game_title2, model: str = DEFAULT_MODEL):\n",
    "    system_prompt = f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Here are two video game titles:\n",
    "1. {game_title1}\n",
    "2. {game_title2}\n",
    "Are these games part of the same franchise? Respond only with 'Yes' or 'No'.\n",
    "    \n",
    "### Response:\n",
    "    \"\"\"\n",
    "      \n",
    "    response = completion(system_prompt, model)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_if_franchise(\"The Legend of Zelda\", \"Legend of Zelda: Breath of the Wild\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_all_pair_candidates(df):\n",
    "    pair_candidates = []\n",
    "    sure_sequal = set()\n",
    "    for _, row in tqdm(df.iterrows()):\n",
    "        game_title = row['title']\n",
    "        for _, row2 in df.iterrows():\n",
    "            game_title2 = row2['title']\n",
    "            if game_title != game_title2:\n",
    "                if check_if_sequel(game_title):\n",
    "                    sure_sequal.append(game_title)\n",
    "                elif check_subname(game_title, game_title2):\n",
    "                    pair_candidates.append((game_title, game_title2))\n",
    "                    \n",
    "    return pair_candidates, sure_sequal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_all_pair_candidates(df):\n",
    "    pair_candidates = []\n",
    "    sure_sequal = set()\n",
    "    \n",
    "    # Create a set of titles for quick lookup and a dictionary to track sequel status\n",
    "    titles = df['title'].tolist()\n",
    "    sequel_status = {title: check_if_sequel(title) for title in titles}\n",
    "    checked_titles = set()  \n",
    "    \n",
    "    for i, title in tqdm(enumerate(titles)):\n",
    "        if sequel_status[title]:  # Check if the current title is a sequel\n",
    "            sure_sequal.add(title)\n",
    "            checked_titles.add(title)\n",
    "        else:\n",
    "            title_row = df[df['title'] == title].iloc[0]    \n",
    "            genre = title_row['genre']\n",
    "            publisher = title_row['publisher']\n",
    "            \n",
    "            cand_df = df[(df['genre'] == genre) & (df['publisher'] == publisher)]\n",
    "            cand_df = cand_df[~cand_df['title'].isin(checked_titles)]\n",
    "            \n",
    "            cand_titles = cand_df['title'].tolist()\n",
    "            # Check for subname pairs with other titles\n",
    "            for title2 in cand_titles:\n",
    "                if title != title2 and check_subname(title, title2):\n",
    "                    pair_candidates.append((title, title2))\n",
    "                    checked_titles.add(title2)\n",
    "                    checked_titles.add(title)\n",
    "                    \n",
    "        checked_titles.add(title)\n",
    "                    \n",
    "    return pair_candidates, sure_sequal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64017it [1:11:14, 14.98it/s] \n"
     ]
    }
   ],
   "source": [
    "pair_candid, sure_sequal = get_all_pair_candidates(video_games_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save to a binary file\n",
    "with open('pair_candid.pkl', 'wb') as file:\n",
    "    pickle.dump(pair_candid, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_check(pair_candidates):\n",
    "    final_pairs = []\n",
    "    for title1, title2 in tqdm(pair_candidates):\n",
    "        response = check_if_franchise(title1, title2)\n",
    "        if response == 'Yes':\n",
    "            final_pairs.append((title1, title2))\n",
    "            \n",
    "    return final_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sequal_column(df, sure_sequal, final_pairs):\n",
    "    df['is_sequal'] = 0\n",
    "    for title in sure_sequal:\n",
    "        df.loc[df['title'] == title, 'is_sequal'] = 1\n",
    "        \n",
    "    for title1, title2 in final_pairs:\n",
    "        date1 = pd.to_datetime(df[df['title'] == title1]['release_date'].values[0])\n",
    "        date2 = pd.to_datetime(df[df['title'] == title2]['release_date'].values[0])\n",
    "        \n",
    "        if date1 > date2:\n",
    "            late_title = title1\n",
    "        else:\n",
    "            late_title = title2\n",
    "            \n",
    "        df.loc[df['title'] == late_title, 'is_sequal'] = 1\n",
    "        \n",
    "        \n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/18986 [00:30<13:28:06,  2.56s/it]"
     ]
    }
   ],
   "source": [
    "final_pairs = last_check(pair_candid)\n",
    "video_games_df = add_sequal_column(video_games_df, sure_sequal, final_pairs)\n",
    "video_games_df = add_week_identifier(df, 'release_date')\n",
    "video_games_df = add_niche(['genre', 'publisher', 'console'], video_games_df)\n",
    "\n",
    "video_games_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_games_df.to_csv('video_games_df_v2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
